{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: 100%|██████████| 19030/19030 [20:49<00:00, 15.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GeoPackage 形式で結果を cam_points.gpkg に保存しました。\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "YOLO11x で人物だけをトラッキングし，\n",
    "頭部（バウンディングボックス上部 HEAD_RATIO %）をモザイク処理する。\n",
    "モザイク付き動画と軌跡（GeoPackage）を出力し，\n",
    "tqdm のプログレスバーで進捗を確認できるスクリプト。\n",
    "\n",
    "追加仕様\n",
    "──────────────────────────────────────────────\n",
    "* 面積フィルタ：バウンディングボックス面積がフレーム全体の 10 % を超えるものは無視\n",
    "* Ultralytics の実行ログ (verbose) を抑制し，代わりに tqdm で進捗を表示\n",
    "\"\"\"\n",
    "\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# ──────────────────────────────────────────────\n",
    "# 設定パラメータ（必要に応じて変更）\n",
    "# ──────────────────────────────────────────────\n",
    "MODEL_PATH   = \"yolo11x.pt\"          # 学習済みモデル\n",
    "VIDEO_PATH   = \"input1.MP4\"\n",
    "OUTPUT_VIDEO = \"output1.mp4\"\n",
    "OUTPUT_GPKG  = \"cam_points.gpkg\"\n",
    "\n",
    "HEAD_RATIO      = 0.30      # 上何 % をモザイクにするか\n",
    "MOS_SCALE       = 0.07      # モザイク粗さ (0.01 細かい, 0.1 粗い)\n",
    "AREA_FRAC_MAX   = 0.05      # バウンディングボックス面積がフレームの 5 % 超なら無視\n",
    "\n",
    "BOX_COLOR  = (255, 0, 0)    # BGR\n",
    "TEXT_COLOR = (255, 255, 255)\n",
    "THICKNESS  = 2\n",
    "\n",
    "# ──────────────────────────────────────────────\n",
    "# モザイク処理関数\n",
    "# ──────────────────────────────────────────────\n",
    "def apply_mosaic(img, x1, y1, x2, y2, scale=MOS_SCALE):\n",
    "    \"\"\"矩形領域 (x1,y1,x2,y2) をピクセル化して img に書き戻す\"\"\"\n",
    "    h, w = img.shape[:2]\n",
    "    x1, y1 = max(0, int(x1)), max(0, int(y1))\n",
    "    x2, y2 = min(w - 1, int(x2)), min(h - 1, int(y2))\n",
    "    if x2 <= x1 or y2 <= y1:\n",
    "        return\n",
    "\n",
    "    roi = img[y1:y2, x1:x2]\n",
    "    small_w = max(1, int((x2 - x1) * scale))\n",
    "    small_h = max(1, int((y2 - y1) * scale))\n",
    "    roi_small  = cv2.resize(roi, (small_w, small_h),\n",
    "                            interpolation=cv2.INTER_LINEAR)\n",
    "    roi_mosaic = cv2.resize(roi_small, (x2 - x1, y2 - y1),\n",
    "                            interpolation=cv2.INTER_NEAREST)\n",
    "    img[y1:y2, x1:x2] = roi_mosaic\n",
    "\n",
    "# ──────────────────────────────────────────────\n",
    "# モデル & 動画 I/O 初期化\n",
    "# ──────────────────────────────────────────────\n",
    "model = YOLO(MODEL_PATH)\n",
    "\n",
    "cap = cv2.VideoCapture(VIDEO_PATH)\n",
    "frame_width   = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "frame_height  = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "fps           = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "frame_count   = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))  # tqdm 用\n",
    "\n",
    "fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")\n",
    "out    = cv2.VideoWriter(OUTPUT_VIDEO, fourcc, fps,\n",
    "                         (frame_width, frame_height))\n",
    "\n",
    "# ──────────────────────────────────────────────\n",
    "# メインループ\n",
    "# ──────────────────────────────────────────────\n",
    "results_list = []\n",
    "\n",
    "with tqdm(total=frame_count, desc=\"Processing\") as pbar:\n",
    "    frame_index = 0\n",
    "    while cap.isOpened():\n",
    "        success, frame = cap.read()\n",
    "        if not success:\n",
    "            break\n",
    "\n",
    "        # ── 人物 (class 0) のみトラッキング ──\n",
    "        yolo_results = model.track(\n",
    "            source=frame,\n",
    "            persist=True,\n",
    "            tracker=\"bytetrack.yaml\",\n",
    "            classes=[0],\n",
    "            verbose=False            # Ultralytics のログ抑制\n",
    "        )\n",
    "\n",
    "        # 検出結果（1フレームにつき 1 Results オブジェクト）\n",
    "        result = yolo_results[0]\n",
    "\n",
    "        # ── 各バウンディングボックスの処理 ──\n",
    "        for box in result.boxes:\n",
    "            x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()\n",
    "            conf   = float(box.conf[0])\n",
    "            obj_id = int(box.id[0]) if box.id is not None else -1\n",
    "            label  = result.names[int(box.cls[0])]\n",
    "\n",
    "            # ― 面積フィルタ ―\n",
    "            area = (x2 - x1) * (y2 - y1)\n",
    "            if area > AREA_FRAC_MAX * frame_width * frame_height:\n",
    "                continue   # 5 % 超は無視\n",
    "\n",
    "            # ― 頭部モザイク ―\n",
    "            head_y2 = y1 + (y2 - y1) * HEAD_RATIO\n",
    "            apply_mosaic(frame, x1, y1, x2, head_y2)\n",
    "\n",
    "            # ― 枠とラベル描画 ―\n",
    "            cv2.rectangle(frame,\n",
    "                          (int(x1), int(y1)),\n",
    "                          (int(x2), int(y2)),\n",
    "                          BOX_COLOR, THICKNESS)\n",
    "            text = f\"id:{obj_id} {conf:.2f}\"\n",
    "            (tw, th), _ = cv2.getTextSize(text,\n",
    "                                          cv2.FONT_HERSHEY_SIMPLEX, 0.6, 1)\n",
    "            cv2.rectangle(frame,\n",
    "                          (int(x1), int(y1 - th - 4)),\n",
    "                          (int(x1 + tw), int(y1)),\n",
    "                          BOX_COLOR, -1)\n",
    "            cv2.putText(frame, text,\n",
    "                        (int(x1), int(y1 - 2)),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.6,\n",
    "                        TEXT_COLOR, 1, cv2.LINE_AA)\n",
    "\n",
    "            # ― 足元中心点座標（研究用） ―\n",
    "            x_center = float((x1 + x2) / 2)\n",
    "            y2_inv   = -float(y2)   # y 軸反転\n",
    "\n",
    "            results_list.append({\n",
    "                \"Frame\": frame_index,\n",
    "                \"ObjectID\": obj_id,\n",
    "                \"x\": x_center,\n",
    "                \"y\": y2_inv\n",
    "            })\n",
    "\n",
    "        # 動画へ書き込み\n",
    "        out.write(frame)\n",
    "\n",
    "        # Esc で中断可（任意）\n",
    "        cv2.imshow(\"YOLO11x Tracking\", frame)\n",
    "        if cv2.waitKey(1) == 27:\n",
    "            break\n",
    "\n",
    "        frame_index += 1\n",
    "        pbar.update(1)\n",
    "\n",
    "# ──────────────────────────────────────────────\n",
    "# 後処理\n",
    "# ──────────────────────────────────────────────\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# DataFrame → GeoDataFrame → GeoPackage\n",
    "df  = pd.DataFrame(results_list)\n",
    "gdf = gpd.GeoDataFrame(df,\n",
    "                       geometry=gpd.points_from_xy(df[\"x\"], df[\"y\"]))\n",
    "gdf.set_crs(\"EPSG:6677\", allow_override=True, inplace=True)\n",
    "gdf.to_file(OUTPUT_GPKG, driver=\"GPKG\")\n",
    "print(f\"GeoPackage 形式で結果を {OUTPUT_GPKG} に保存しました。\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "画面サイズ: 幅=2704px, 高さ=1520px\n",
      "00:00の画像をback.pngとして保存しました\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "# 動画ファイルを読み込み\n",
    "cap = cv2.VideoCapture('output1.mp4')\n",
    "\n",
    "# 読み込み成功確認\n",
    "if not cap.isOpened():\n",
    "    print(\"動画ファイルを開けませんでした\")\n",
    "else:\n",
    "    # 最初のフレームを取得（00:00）\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    if ret:\n",
    "        # フレームのサイズを取得\n",
    "        height, width = frame.shape[:2]\n",
    "        print(f\"画面サイズ: 幅={width}px, 高さ={height}px\")\n",
    "\n",
    "        # 画像として保存\n",
    "        cv2.imwrite('back.png', frame)\n",
    "        print(\"00:00の画像をback.pngとして保存しました\")\n",
    "    else:\n",
    "        print(\"フレームを取得できませんでした\")\n",
    "\n",
    "# 開放\n",
    "cap.release()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mesa3_tensorflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
